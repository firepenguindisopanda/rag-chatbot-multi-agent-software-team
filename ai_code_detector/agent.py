"""
AI Code Detection Agent

Orchestrates the ensemble of detection tools using LangChain.
"""

from typing import Dict, Any, List
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import BaseTool

from .tools import (
    LoaderTool,
    MetadataExtractor,
    ASTFeatureExtractor,
    StaticAnalyzerWrapper,
    LMScorer,
    EmbeddingFAISSSearch,
    StylometryComparator,
    ScoringAggregator,
    ReportWriter
)


class AICodeDetectionAgent:
    """Agent that orchestrates AI code detection using multiple tools."""

    def __init__(self, llm=None):
        """Initialize the detection agent."""
        self.llm = llm
        self.tools = self._initialize_tools()
        self.agent_executor = self._create_agent()

    def _initialize_tools(self) -> List[BaseTool]:
        """Initialize all detection tools."""
        return [
            LoaderTool(),
            MetadataExtractor(),
            ASTFeatureExtractor(),
            StaticAnalyzerWrapper(),
            LMScorer(),
            EmbeddingFAISSSearch(),
            StylometryComparator(),
            ScoringAggregator(),
            ReportWriter()
        ]

    def _create_agent(self):
        """Create the LangChain agent with tools."""
        if not self.llm:
            return None  # Fallback for when LLM is not available

        # Define the agent prompt
        prompt = ChatPromptTemplate.from_messages([
            ("system", """You are an AI code detection specialist. Your task is to analyze code submissions
            to determine if they were likely generated by AI systems.

            Follow this workflow:
            1. Load and parse the submission
            2. Extract metadata and features
            3. Run static analysis
            4. Compute language model scores
            5. Check embedding similarity
            6. Compare stylometry to student baseline
            7. Aggregate scores
            8. Generate comprehensive report

            Be thorough and consider multiple signals. Always provide evidence for your conclusions."""),
            ("human", "{input}"),
            ("placeholder", "{agent_scratchpad}")
        ])

        # Create agent with tools
        agent = create_openai_tools_agent(self.llm, self.tools, prompt)
        return AgentExecutor(agent=agent, tools=self.tools, verbose=True)

    def detect_ai_code(self, submission_path: str, student_id: str = "unknown") -> Dict[str, Any]:
        """Run complete AI detection analysis on a submission."""
        try:
            # For now, run tools sequentially since agent orchestration is complex
            # In production, this would use the LangChain agent

            results = {}

            # Step 1: Load submission
            loader = LoaderTool()
            load_result = loader._run(submission_path)
            results["loaded_data"] = load_result

            if "chunks" not in load_result or not load_result["chunks"]:
                return {"error": "Failed to load submission"}

            # Process first chunk for analysis (simplified)
            chunk = load_result["chunks"][0]
            code = chunk["text"]
            language = chunk["language"]

            # Step 2: Extract metadata
            metadata_tool = MetadataExtractor()
            metadata = metadata_tool._run(chunk["file_path"])
            results["metadata"] = metadata

            # Step 3: AST features
            ast_tool = ASTFeatureExtractor()
            ast_features = ast_tool._run(code, language)
            results["ast_features"] = ast_features

            # Step 4: Static analysis
            static_tool = StaticAnalyzerWrapper()
            static_results = static_tool._run(code, language)
            results["static_analysis"] = static_results

            # Step 5: LM scoring
            lm_tool = LMScorer()
            lm_score = lm_tool._run(code, language)
            results["lm_score"] = lm_score.get("lm_score", 0.5)

            # Step 6: Embedding similarity
            embed_tool = EmbeddingFAISSSearch()
            similarity = embed_tool._run(code, language)
            results["similarity_score"] = similarity.get("similarity_score", 0.0)

            # Step 7: Stylometry comparison
            stylometry_tool = StylometryComparator()
            combined_features = {**ast_features.get("features", {}), **static_results}
            stylometry = stylometry_tool._run(combined_features, student_id)
            results["stylometry_distance"] = stylometry.get("stylometry_distance", 0.5)

            # Step 8: Aggregate scores
            aggregator = ScoringAggregator()
            scores = {
                "lm_score": results["lm_score"],
                "faiss_similarity": results["similarity_score"],
                "stylometry_distance": results["stylometry_distance"],
                "provenance_score": 0.0,  # Placeholder
                "dynamic_anomaly": 0.0    # Placeholder
            }
            aggregated = aggregator._run(scores)
            results.update(aggregated)

            # Step 9: Generate report
            report_tool = ReportWriter()
            report = report_tool._run(results, student_id, f"submission_{submission_path}")
            results["report"] = report

            return results

        except Exception as e:
            return {"error": f"Detection failed: {str(e)}"}


def run_ai_detection(submission_path: str, student_id: str = "unknown") -> Dict[str, Any]:
    """Convenience function to run AI detection."""
    agent = AICodeDetectionAgent()
    return agent.detect_ai_code(submission_path, student_id)